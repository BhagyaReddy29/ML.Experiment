{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhagyaReddy29/ML.Experiment/blob/main/ML_Lab14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine Algorithm**\n",
        "\n",
        "Support Vector Machine or SVM is one of the most popular Supervised Learning algorithms, which is used for Classification as well as Regression problems. However, primarily, it is used for Classification problems in Machine Learning.\n",
        "\n",
        "The goal of the SVM algorithm is to create the best line or decision boundary that can segregate n-dimensional space into classes so that we can easily put the new data point in the correct category in the future. This best decision boundary is called a hyperplane.\n",
        "\n",
        "SVM chooses the extreme points/vectors that help in creating the hyperplane. These extreme cases are called as support vectors, and hence algorithm is termed as Support Vector Machine"
      ],
      "metadata": {
        "id": "ltkLciKbG7UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**14. Write a program to Implement Support Vector Machines and Principle Component Analysis**"
      ],
      "metadata": {
        "id": "-Frfnx7EHEeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/Lab14.csv\"  # Replace with the correct path to your dataset\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(dataset.head())\n",
        "\n",
        "# Preprocess the data\n",
        "# Assuming you have a categorical 'Gender' column that needs to be converted\n",
        "dataset['Gender'] = dataset['Gender'].map({'Male': 1, 'Female': 0})\n",
        "\n",
        "# Select features and target\n",
        "X = dataset[['Gender', 'Age', 'EstimatedSalary']]\n",
        "y = dataset['Purchased']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# Train SVM model\n",
        "svm = SVC(kernel='linear', random_state=42)\n",
        "svm.fit(X_train_pca, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nAccuracy Score:\")\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "afMNtfUZHGjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the decision boundary and data points\n",
        "# Create a meshgrid for plotting decision regions\n",
        "h = 0.01  # Step size in the mesh\n",
        "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
        "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "# Predict the class labels for the grid points\n",
        "Z = svm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot the decision boundary and the original data points\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
        "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_train, s=30, edgecolors='k', cmap=plt.cm.coolwarm)\n",
        "plt.title('SVM Decision Boundary with PCA (Training Set)')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()\n",
        "\n",
        "# Plot the test data points and decision boundary\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\n",
        "plt.scatter(X_test_pca[:, 0], X_test_pca[:, 1], c=y_test, s=30, edgecolors='k', cmap=plt.cm.coolwarm)\n",
        "plt.title('SVM Decision Boundary with PCA (Test Set)')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z0UXJevTHM4A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}