{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhagyaReddy29/ML.Experiment/blob/main/ML_Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Decision tree :** A decision tree is a popular and intuitive machine learning algorithm used for both classification and regression tasks. It models decisions and their possible consequences in a tree-like structure, where each internal node represents a feature (or attribute), each branch represents a decision rule, and each leaf node represents an outcome (or class label)."
      ],
      "metadata": {
        "id": "CnHdWmSrT2LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**ID3 algorithm :** The ID3 algorithm (Iterative Dichotomiser 3) is a popular algorithm used for creating decision trees in machine learning, primarily for classification tasks. It was developed by Ross Quinlan in 1986 and is known for its simplicity and effectiveness.\n",
        "\n",
        "It uses the tree representation to solve a problem in which each node represents an attribute, each link represents a decision rule and each leaf represents an outcome( categorical or continuous value)."
      ],
      "metadata": {
        "id": "e4zIiq9JT51B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Write a program to demonstrate the working of the decision tree based ID3 algorithm. Use an appropriate data set for building the decision tree and apply this knowledge to classify a new sample.**"
      ],
      "metadata": {
        "id": "phcalimyT8lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/PlayTennis.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Preview the data\n",
        "print(\"Dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "U8gbrhGWUMIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Prepare the data for training\n",
        "# Assume that the target column is the last column ('PlayTennis') and the rest are features\n",
        "X = df.iloc[:, :-1]  # All columns except the last one as features\n",
        "y = df.iloc[:, -1]   # The last column as the target\n",
        "\n",
        "# Convert categorical features into numerical values using one-hot encoding\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create the Decision Tree classifier using ID3 algorithm (entropy)\n",
        "clf = DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the model's accuracy on the test data\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print(f\"Accuracy of the model: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Visualize the decision tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "tree.plot_tree(clf, filled=True, feature_names=X.columns, class_names=clf.classes_, rounded=True)\n",
        "plt.show()\n",
        "\n",
        "# Classify a new sample\n",
        "# Example: {'Outlook': 'Sunny', 'Temperature': 'Hot', 'Humidity': 'High', 'Wind': 'Weak'}\n",
        "new_sample = pd.DataFrame({\n",
        "    'Outlook': ['Sunny'],\n",
        "    'Temperature': ['Hot'],\n",
        "    'Humidity': ['High'],\n",
        "    'Wind': ['Weak']\n",
        "})\n",
        "\n",
        "# Convert the new sample into the same format (one-hot encoding)\n",
        "new_sample_encoded = pd.get_dummies(new_sample)\n",
        "new_sample_encoded = new_sample_encoded.reindex(columns=X.columns, fill_value=0)\n",
        "\n",
        "# Predict the class of the new sample\n",
        "predicted_class = clf.predict(new_sample_encoded)\n",
        "print(f\"Predicted class for the new sample: {predicted_class[0]}\")"
      ],
      "metadata": {
        "id": "pdhIm5KGUj-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Load Dataset:** We load the PlayTennis.csv dataset using pandas to explore and process it.\n",
        "\n",
        "2. **Separate Features and Target:**\n",
        "\n",
        "X: This contains all the columns except the target column (PlayTennis), which represent the input features (Outlook, Temperature, Humidity, Wind).\n",
        "\n",
        "y: This contains only the target column (PlayTennis), which tells whether to play tennis (Yes/No).\n",
        "\n",
        "3.** Convert Categorical to Numerical (One-Hot Encoding):** Since decision trees require numerical data, we convert the categorical data (like \"Sunny\", \"Rain\", etc.) into numerical values using one-hot encoding. This creates new binary columns for each category.\n",
        "\n",
        "4. **Split the Data:** We split the data into a training set (70%) to train the decision tree and a test set (30%) to evaluate its accuracy.\n",
        "\n",
        "5.**Train the Decision Tree** (ID3 Algorithm): We create a decision tree using the ID3 algorithm, which splits the data based on entropy (a measure of information gain).\n",
        "\n",
        "6. **Evaluate Model Accuracy:** The model's accuracy on the test set is printed to see how well it performs.\n",
        "\n",
        "7. **Visualize the Decision Tree:** We visualize the tree to understand how it makes decisions based on the features.\n",
        "\n",
        "8. **Classify a New Sample:** We create a new data sample (e.g., \"Sunny\", \"Hot\", \"High\", \"Weak\") and use the trained decision tree to predict whether to play tennis or not."
      ],
      "metadata": {
        "id": "G_s-u8etVHht"
      }
    }
  ]
}